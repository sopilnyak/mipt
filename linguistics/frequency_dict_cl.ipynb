{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание по компьютерной лингвистике\n",
    "### Сопильняк Ольга, группа 495\n",
    "\n",
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для создания корпуса текстов используются следующие произведения Фёдора Михайловича Достоевского:\n",
    "* \"Преступление и наказание\"\n",
    "* \"Братья Карамазовы\"\n",
    "* \"Бедные люди\"\n",
    "* \"Бесы\"\n",
    "* \"Подросток\"\n",
    "\n",
    "В рамках работы с помощью библиотек NLTK и pymorphy2 был проведен частотный анализ лемм, словоформ, n-грамм словосочетаний и частей речи, а также грамматических категорий, встречающихся в текстах Достоевского. Описан алгоритм, который использует библиотека pymorphy2. Приведены некоторые выводы о возможных способах идентификации авторства на основе полученных данных. В конце задания сформулирован алгоритм формирования относительных придаточных предложений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 1. Частотный словарь и закон Ципфа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем все файлы и запишем в одну строку, чтобы в дальнейшем было удобнее работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cat(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = cat('dost1.txt')\n",
    "data += cat('dost2.txt')\n",
    "data += cat('dost3.txt')\n",
    "data += cat('dost4.txt')\n",
    "data += cat('dost5.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем текст на токены и уберем пунктуацию и прочие посторонние символы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = nltk.word_tokenize(data)\n",
    "words = [word.lower() for word in words if word.isalpha()]  # remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "933294"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаточно много слов, корпус должен получиться неплохой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['достоевский', 'преступление', 'и', 'наказание', 'часть', 'в', 'начале', 'июля', 'в', 'чрезвычайно', 'жаркое', 'время', 'под', 'вечер', 'один', 'молодой', 'человек', 'вышел', 'из', 'своей', 'каморки', 'которую', 'нанимал', 'от', 'жильцов', 'в', 'переулке', 'на', 'улицу', 'и', 'медленно', 'как', 'бы', 'в', 'нерешимости', 'отправился', 'к', 'мосту', 'он', 'благополучно', 'избегнул', 'встречи', 'с', 'своею', 'хозяйкой', 'на', 'лестнице', 'каморка', 'его', 'приходилась', 'под', 'самою', 'кровлей', 'высокого', 'пятиэтажного', 'дома', 'и', 'походила', 'более', 'на', 'шкаф', 'чем', 'на', 'квартиру', 'квартирная', 'же', 'хозяйка', 'его', 'у', 'которой', 'он', 'нанимал', 'эту', 'каморку', 'с', 'обедом', 'и', 'прислугой', 'помещалась', 'одною', 'лестницей', 'ниже', 'в', 'отдельной', 'квартире', 'и', 'каждый', 'раз', 'при', 'выходе', 'на', 'улицу', 'ему', 'непременно', 'надо', 'было', 'проходить', 'мимо', 'хозяйкиной', 'кухни']\n"
     ]
    }
   ],
   "source": [
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотека pymorphy2\n",
    "\n",
    "В NLTK лемматизатора для русского языка нет, поэтому будем использовать библиотеку pymorphy2. Она использует словари OpenCorpora, в которой для каждого слова имеются его лексемы.\n",
    "\n",
    "В общих чертах лемматизатор pymorphy2 работает так: \n",
    "\n",
    "* каждое слово можно разбить на префикс + стем + окончание\n",
    "* если откинуть стем, можно получить набор правил\n",
    "* для каждой лексемы определяется ее парадигма и удаляются дубликаты\n",
    "* хранятся только парадигмы и информация о том, по какой парадигме слово изменяется\n",
    "* для парадигм используется числовое представление для компактности\n",
    "\n",
    "Если по словарю слово найти нельзя, то в дело идут правила разбора несловарных слов: \n",
    "* отсечение неизвестных префиксов\n",
    "* предсказание по концу слова (когда отсечение префиксов использовать нельзя: правая часть неизвестна либо приставка влияет на разбор)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip3 install pymorphy2\n",
    "!pip install -U pymorphy2-dicts-ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применим лемматизатор pymorphy2 и посмотрим, что получается. Однако, недостаток такого разбора -- отсутствие снятия омонимии. Библиотека pymorphy2 выдает все возможные разборы слова и, согласно документации pymorphy2, наиболее вероятный разбор (первый в списке) верен примерно в 79% случаев.\n",
    "\n",
    "Вероятность правильности разбора определяется как условная вероятность P(tag|word). Она оценивается на основе корпуса OpenCorpora: ищутся все неоднозначные слова со снятой неоднозначностью, для каждого слова считается, сколько раз ему был сопоставлен данный тег, и на основе этих частот вычисляется условная вероятность тега."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "достоевский -> достоевский\n",
      "преступление -> преступление\n",
      "и -> и\n",
      "наказание -> наказание\n",
      "часть -> часть\n",
      "в -> в\n",
      "начале -> начало\n",
      "июля -> июль\n",
      "в -> в\n",
      "чрезвычайно -> чрезвычайно\n",
      "жаркое -> жаркое\n",
      "время -> время\n",
      "под -> под\n",
      "вечер -> вечер\n",
      "один -> один\n",
      "молодой -> молодая\n",
      "человек -> человек\n",
      "вышел -> выйти\n",
      "из -> из\n",
      "своей -> свой\n",
      "каморки -> каморка\n",
      "которую -> который\n",
      "нанимал -> нанимать\n",
      "от -> от\n",
      "жильцов -> жильцов\n",
      "в -> в\n",
      "переулке -> переулок\n",
      "на -> на\n",
      "улицу -> улица\n",
      "и -> и\n",
      "медленно -> медленно\n",
      "как -> как\n",
      "бы -> бы\n",
      "в -> в\n",
      "нерешимости -> нерешимость\n",
      "отправился -> отправиться\n",
      "к -> к\n",
      "мосту -> мост\n",
      "он -> он\n",
      "благополучно -> благополучно\n",
      "избегнул -> избегнуть\n",
      "встречи -> встреча\n",
      "с -> с\n",
      "своею -> свой\n",
      "хозяйкой -> хозяйка\n",
      "на -> на\n",
      "лестнице -> лестница\n",
      "каморка -> каморка\n",
      "его -> он\n",
      "приходилась -> приходиться\n"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "for word in words[:50]:\n",
    "    print(word + \" -> \" + morph.parse(word)[0].normal_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается вполне хорошо, поэтому применим алгоритм ко всем словам в списке слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_lemmatized = [morph.parse(word)[0].normal_form for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь построим по этим данным частотный словарь и запишем его в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_freq_dict(wordlist):\n",
    "    \n",
    "    dictionary = FreqDist(wordlist)\n",
    "    \n",
    "    import operator\n",
    "    dictionary = sorted(dictionary.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    for i in range(len(dictionary)):\n",
    "        dictionary[i] = (dictionary[i][0], dictionary[i][1] / len(wordlist))\n",
    "        \n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = find_freq_dict(words_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('и', 0.047514502396886725), ('я', 0.02795046362668141), ('в', 0.02616110250360551), ('он', 0.026023953866627238), ('не', 0.023119188594376477), ('что', 0.020050487841987628), ('быть', 0.014209884559420719), ('с', 0.013773794752778868), ('на', 0.012389450698279427), ('весь', 0.011901930152770725), ('вы', 0.010602232522656312), ('это', 0.010396509567188903), ('а', 0.009728981435646216), ('она', 0.009473970688764741), ('как', 0.009110741095517598), ('но', 0.00806926863346384), ('к', 0.00654134709962777), ('же', 0.0064481288854316005), ('так', 0.00614490182086245), ('тот', 0.005446300951254374)]\n"
     ]
    }
   ],
   "source": [
    "print(dictionary[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = open('out_freq.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % dictionary[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, выполняется ли закон Ципфа: частота слов обратно пропорциональна их индексам в отсортированном частотном словаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7kAAAJPCAYAAAC5GxNwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAADoDZELAABAb/z/FxpgojuOIsoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb8db6aacc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 10))\n",
    "plt.plot([dictionary[i][1] for i in range(len(dictionary))], label='real')\n",
    "plt.plot([0.1 / i for i in range(1, len(dictionary))], label='Zipf\\'s law')\n",
    "plt.ylim(ymax=0.01)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видно, что примерное совпадение наблюдается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 2. N-граммы на уровне словосочетаний"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь построим n-граммы (для n = 3, n = 4) словосочетаний, встречающихся в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_ngrams_statistics(words_array, n, is_freq=True):\n",
    "    \n",
    "    from nltk import ngrams\n",
    "    \n",
    "    sentence_pos = ' '.join(str(word) for word in words_array)\n",
    "    \n",
    "    sixgrams = ngrams(sentence_pos.split(), n)\n",
    "    ngrams = []\n",
    "    for grams in sixgrams:\n",
    "        ngrams.append(' '.join(grams))\n",
    "    \n",
    "    ngrams_statistics = {}\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        if not ngram in ngrams_statistics:\n",
    "            ngrams_statistics.update({ngram : 1})\n",
    "        else:\n",
    "            ngram_occurrences = ngrams_statistics[ngram]\n",
    "            ngrams_statistics.update({ngram : ngram_occurrences + 1})\n",
    "            \n",
    "    import operator\n",
    "    ngrams_statistics_sorted = sorted(ngrams_statistics.items(), \\\n",
    "                               key=operator.itemgetter(1), \\\n",
    "                               reverse=True)\n",
    "    \n",
    "    if is_freq:\n",
    "        ngrams_statistics_sorted = [(number[0], number[1] / len(ngrams)) \n",
    "                                for number in ngrams_statistics_sorted]\n",
    "\n",
    "    return ngrams_statistics_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams = find_ngrams_statistics(words, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('по крайней мере', 0.00032358575879788963),\n",
       " ('в самом деле', 0.00026465457755986334),\n",
       " ('до сих пор', 0.00024858243722221987),\n",
       " ('в том что', 0.0002057233963218371),\n",
       " ('а между тем', 0.0001917942080292127),\n",
       " ('в то же', 0.00017465059166905963),\n",
       " ('может быть и', 0.00017465059166905963),\n",
       " ('о том что', 0.00017357911564655007),\n",
       " ('к тому же', 0.00017036468757902136),\n",
       " ('и как бы', 0.00016179287939894482)]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('out_3grams.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % ngrams[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams = find_ngrams_statistics(words, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('в то же время', 0.0001542927125623198),\n",
       " ('несмотря на то что', 8.464669647516155e-05),\n",
       " ('ни за что не', 7.39319247694449e-05),\n",
       " ('и в то же', 6.964601608715823e-05),\n",
       " ('и в самом деле', 6.536010740487157e-05),\n",
       " ('до сих пор не', 4.92879498462966e-05),\n",
       " ('соч в т с', 4.714499550515327e-05),\n",
       " ('собр соч в т', 4.393056399343828e-05),\n",
       " ('дело в том что', 4.285908682286661e-05),\n",
       " ('с там же с', 3.964465531115161e-05)]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('out_4grams.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % ngrams[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 3. N-граммы на уровне частей речи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека pymorphy2, основываясь на данных OpenCorpora, позволяет определить часть речи слова. Построим n-граммы по этим данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = [morph.parse(word)[0].tag for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "достоевский -> NOUN\n",
      "преступление -> NOUN\n",
      "и -> CONJ\n",
      "наказание -> NOUN\n",
      "часть -> NOUN\n",
      "в -> PREP\n",
      "начале -> NOUN\n",
      "июля -> NOUN\n",
      "в -> PREP\n",
      "чрезвычайно -> ADVB\n",
      "жаркое -> NOUN\n",
      "время -> NOUN\n",
      "под -> PREP\n",
      "вечер -> NOUN\n",
      "один -> ADJF\n",
      "молодой -> NOUN\n",
      "человек -> NOUN\n",
      "вышел -> VERB\n",
      "из -> PREP\n",
      "своей -> ADJF\n"
     ]
    }
   ],
   "source": [
    "for word in words[:20]:\n",
    "    print(word + \" -> \" + morph.parse(word)[0].tag.POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos = [tag.POS for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_ngrams_statistics(words_array, n, is_freq=True):\n",
    "    \n",
    "    from nltk import ngrams\n",
    "    \n",
    "    sentence_pos = ' '.join(str(word) for word in words_array)\n",
    "    \n",
    "    sixgrams = ngrams(sentence_pos.split(), n)\n",
    "    ngrams = []\n",
    "    for grams in sixgrams:\n",
    "        ngrams.append(' '.join(grams))\n",
    "    \n",
    "    ngrams_statistics = {}\n",
    "\n",
    "    for ngram in ngrams:\n",
    "        if not ngram in ngrams_statistics:\n",
    "            ngrams_statistics.update({ngram : 1})\n",
    "        else:\n",
    "            ngram_occurrences = ngrams_statistics[ngram]\n",
    "            ngrams_statistics.update({ngram : ngram_occurrences + 1})\n",
    "            \n",
    "    import operator\n",
    "    ngrams_statistics_sorted = sorted(ngrams_statistics.items(), \\\n",
    "                               key=operator.itemgetter(1), \\\n",
    "                               reverse=True)\n",
    "    \n",
    "    if is_freq:\n",
    "        ngrams_statistics_sorted = [(number[0], number[1] / len(ngrams)) \n",
    "                                for number in ngrams_statistics_sorted]\n",
    "\n",
    "    return ngrams_statistics_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ngrams_statistics = find_ngrams_statistics(pos, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('PREP ADJF NOUN', 0.015923205170514695),\n",
       " ('NOUN PREP NOUN', 0.012606986880847581),\n",
       " ('ADJF NOUN CONJ', 0.010029015570689559),\n",
       " ('PREP NOUN NOUN', 0.009711858668026726),\n",
       " ('VERB PREP NOUN', 0.009374343720936212),\n",
       " ('NOUN NOUN NOUN', 0.00921040788949225),\n",
       " ('PREP NOUN CONJ', 0.00848716157429829),\n",
       " ('ADJF NOUN NOUN', 0.00799213965189887),\n",
       " ('NOUN ADJF NOUN', 0.007909635998165633),\n",
       " ('NOUN PREP ADJF', 0.007500332157566978),\n",
       " ('ADJF ADJF NOUN', 0.007443543928373971),\n",
       " ('ADJF NOUN PREP', 0.00702352532755022),\n",
       " ('ADJF NOUN VERB', 0.006806015694980778),\n",
       " ('NOUN NOUN CONJ', 0.006531717833218328),\n",
       " ('NOUN NOUN VERB', 0.006466357795845245),\n",
       " ('NOUN CONJ NOUN', 0.006275635063838541),\n",
       " ('PREP NOUN VERB', 0.005795613805754255),\n",
       " ('CONJ NPRO VERB', 0.005537388084329449),\n",
       " ('PREP NOUN PREP', 0.005384167013110581),\n",
       " ('ADJF NOUN ADJF', 0.005326307307895064)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_statistics[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = open('out_ngrams_pos.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % ngrams_statistics[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 4. Статистика по различным грамматическим значениям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Падеж"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "case = [tag.case for tag in tags]\n",
    "case = list(filter(lambda a: a != None, case))\n",
    "dict_case = find_freq_dict(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nomn', 0.39883146203005815),\n",
       " ('gent', 0.2428336542957849),\n",
       " ('accs', 0.1357822014169277),\n",
       " ('datv', 0.08235075246001378),\n",
       " ('ablt', 0.07285763848733665),\n",
       " ('loct', 0.06296730205499772),\n",
       " ('loc2', 0.002026337357515298),\n",
       " ('gen2', 0.0013173706890049828),\n",
       " ('voct', 0.0010332812083607785)]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_case[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output = open('out_case.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % dict_case[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобладает именительный падеж. Как покажет позже сравнение с другими авторами, это скорее особенность языка, а не автора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Время"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tense = [tag.tense for tag in tags]\n",
    "tense = list(filter(lambda a: a != None, tense))\n",
    "dict_tense = find_freq_dict(tense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('past', 0.6401405628238528),\n",
       " ('pres', 0.2675918238813661),\n",
       " ('futr', 0.09226761329478114)]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_tense[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('out_tense.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % dict_tense[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут преобладает прошедшее время. Это, во-первых, можно объяснить жанром (все выбранные произведения Достоевского -- романы), а во-вторых, можно списать на авторскую специфику."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Род"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gender = [tag.gender for tag in tags]\n",
    "gender = list(filter(lambda a: a != None, gender))\n",
    "dict_gender = find_freq_dict(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('masc', 0.513381864623244),\n",
       " ('femn', 0.3059693486590038),\n",
       " ('neut', 0.18064878671775222)]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_gender[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('out_gender.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % dict_gender[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "51% -- мужской род, 31% -- женский, 18% -- средний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Залог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voice = [tag.voice for tag in tags]\n",
    "voice = list(filter(lambda a: a != None, voice))\n",
    "dict_voice = find_freq_dict(voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pssv', 0.5812000819168543), ('actv', 0.4187999180831456)]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_voice[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('out_voice.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % dict_voice[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе этой характеристики также можно анализировать специфику автора: 58% пассивного залога, 42% -- активного."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Включенность говорящего в действие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "involvement = [tag.involvement for tag in tags]\n",
    "involvement = list(filter(lambda a: a != None, involvement))\n",
    "dict_involvement = find_freq_dict(involvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('excl', 0.9885553159727981), ('incl', 0.011444684027201857)]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_involvement[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('out_involvement.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % dict_involvement[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Лицо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "person = [tag.person for tag in tags]\n",
    "person = list(filter(lambda a: a != None, person))\n",
    "dict_person = find_freq_dict(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('3per', 0.4696981059753852),\n",
       " ('1per', 0.35294852886033545),\n",
       " ('2per', 0.17735336516427935)]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_person[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('out_person.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % dict_person[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь опять же скорее специфика жанра: мало диалогов и много описаний, поэтому преобладает третье лицо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Одушевленность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "animacy = [tag.animacy for tag in tags]\n",
    "animacy = list(filter(lambda a: a != None, animacy))\n",
    "dict_animacy = find_freq_dict(animacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inan', 0.6859975303232488), ('anim', 0.31400246967675116)]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_animacy[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = open('out_animacy.txt', 'w', encoding=\"utf-8\")\n",
    "output.write('%s' % dict_animacy[:1000])\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вполне вероятно, что эта грамматическая категория не несет много информации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 5. Сравнение с другими авторами и выводы о возможных способах идентификации авторства"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было проведено сравнение с корпусами текстов А.С. Грибоедова (Ирина Гавенко) и М.Е. Салтыкова-Щедрина (Павел Воропаев).\n",
    "\n",
    "### Частота лексем\n",
    "\n",
    "Список наиболее часто встречающихся лексем у всех авторов практически совпадает со аналогичным общим списком для русского языка, поэтому такой признак вряд ли можно использовать для идентификации авторства. Однако, интерес могут представлять частотные словари с отсечением наиболее часто встречающихся слов (предлогов, личных местоимений и пр.)\n",
    "\n",
    "### N-граммы на уровне словосочетаний\n",
    "\n",
    "Хорошо заметна авторская специфика: уникальные наиболее часто встречающиеся словосочетания. Для Достоевского это \"может быть и\", \"в самом деле\", \"несмотря на то что\". Для Салтыкова-Щедрина -- \"с одной стороны\", \"с другой стороны\", \"тем не менее\", \"не только не\", \"до такой степени\". Также встречаются и общие, часто встречающиеся в русском языке как таковом: \"по крайней мере\", \"в то же время\". Для Грибоедова данные могут быть испорчены небольшим объемом корпуса, но прослеживаются часто встречающиеся разговорные выражения: \"ах боже мой\", \"ха ха ха\", \"с ума сошел\", а также характерное для пьесы \"в сторону\".\n",
    "\n",
    "Однако, для идентификации авторства одного (возможно, небольшого) произведения такой способ может не подойти, потому что часто употребляемые автором выражения заметны только на достаточно больших данных.\n",
    "\n",
    "\n",
    "### N-граммы на уровне частей речи\n",
    "\n",
    "Здесь встречаемость у Достоевского и Салтыкова-Щедрина почти совпадает, а у Грибоедова отличается: он гораздо реже использует такую, казалось бы, часто встречающуюся конструкцию, как \"прилагательное - существительное\" или \"предлог - прилагательное - сущестительное\", заменяя его \"существительное - предлог - существительное\" и 3 существительных подряд.\n",
    "\n",
    "### Статистика по различным грамматическим значениям\n",
    "\n",
    "Встречаемость **падежей** практически совпадает, поэтому скорее всего этот параметр нельзя использовать для идентификации авторства.\n",
    "\n",
    "У Достоевского преобладает прошедшее **время**, у Грибоедова -- настоящее. Так как Достоевский писал романы, а Грибоедов -- пьесы, это легко объясняется. А вот у Салтыкова-Щедрина, хотя тоже преобладает прошедшее время, его меньше, чем у Достоевского, это можно объяснить авторством.\n",
    "\n",
    "**Род** тоже практически совпадает: это тоже можно объяснить особенностями языка.\n",
    "\n",
    "Соотношение пассивного и активного **залогов** у Достоевского и Грибоедова сильно различаются, причем, как ни странно, у Достоевского они встречаются почти в равной степени, а у Грибоедова сильно преобладает пассивный.\n",
    "\n",
    "**Лицо** -- скорее всего особенность жанра: в пьесе из-за большого количества диалогов первое лицо встречается чаще. У Салтыкова больше третьего лица, чем у Достоевского, хотя у обоих третье лицо преобладает.\n",
    "\n",
    "### Выводы\n",
    "\n",
    "К признакам, позволяющим идентифицировать авторство, можно отнести время и залог, а также наиболее часто встречающиеся n-граммы по леммам, словоформам и частям речи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Часть 6. Алгоритм формирования относительных придаточных предложений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Сделать главным слово, относительно которого происходит формирование относительного придаточного;\n",
    "* добавить относительное местоимение после главного и построить зависимость от главного слова к нему;\n",
    "* слово, которое было главным до применения алгоритма, поставить после относительного местоимения и построить зависимость от относительного местоимения к нему;\n",
    "* непосредственно зависимое от него поставить следующим.\n",
    "\n",
    "\"Джек построил дом\" -> \"Дом, который построил Джек\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
